{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1144b0",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithm Implementation\n",
    "Yale Machine Learning CPSC 581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b2f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General Libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Statistic & Machine Learning Libraries\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "# import statsmodels.formula.api as smf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn import tree\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110847fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f918b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56669</td>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "5  56669    Male  81.0             0              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "5        Private          Urban             186.21  29.0  formerly smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.copy()\n",
    "\n",
    "df = df.dropna() # Missing observation is removed.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c64f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"stroke\"]\n",
    "X = df.drop([\"stroke\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524739f4",
   "metadata": {},
   "source": [
    "Preprocess the data. Using the same form as what Burak Kahveci did.\n",
    "Quote: https://www.kaggle.com/burakkahveci/stroke-risk-prediction-with-machine-learning/notebook#My-Social-Media-Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07051bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease  ever_married  Residence_type  \\\n",
       "0       1  67.0             0              1             1               1   \n",
       "2       1  80.0             0              1             1               0   \n",
       "3       0  49.0             0              0             1               1   \n",
       "4       0  79.0             1              0             1               0   \n",
       "5       1  81.0             0              0             1               1   \n",
       "\n",
       "   avg_glucose_level   bmi  smoking_status  \n",
       "0             228.69  36.6               1  \n",
       "2             105.92  32.5               0  \n",
       "3             171.23  34.4               0  \n",
       "4             174.12  24.0               0  \n",
       "5             186.21  29.0               1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['smoking_status'] = X['smoking_status'].replace({'formerly smoked' or 'smokes':'smoked','never smoked' or 'Unknown':'non_smoking'})\n",
    "#4 Status downgraded to Status 2.\n",
    "X['smoking_status'] = [1 if i.strip() == 'smoked' else 0 for i in X.smoking_status]\n",
    "X['gender'] = [1 if i.strip() == 'Male' else 0 for i in X.gender]\n",
    "X['ever_married'] = [1 if i.strip() == 'Yes' else 0 for i in X.ever_married]\n",
    "X['Residence_type'] = [1 if i.strip() == 'Urban' else 0 for i in X.Residence_type]\n",
    "\n",
    "X = X.drop([\"work_type\"], axis=1)\n",
    "X = X.drop([\"id\"], axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ecf83",
   "metadata": {},
   "source": [
    "## Implementation of Logistic Regression with l2 regulization\n",
    "\n",
    "I read the implementation of logistic regression in this article\n",
    "https://www.geeksforgeeks.org/implementation-of-logistic-regression-from-scratch-using-python/\n",
    "But I choose to add a column of 1s and add a dimention to weight so that I can use the form \"w . x\" instead of \"w . x + b\"\n",
    "Also, I add a regulization each step when update the weight w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "795bf67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogitRegression() :\n",
    "    def __init__( self, learning_rate, iterations, reg = 1) :        \n",
    "        self.learning_rate = learning_rate        \n",
    "        self.iterations = iterations\n",
    "        self.reg = reg\n",
    "          \n",
    "    # Function for model training    \n",
    "    def fit( self, X, Y ) :        \n",
    "        # m is num_of_training_examples, n is num_of_features        \n",
    "        self.m, self.n = X.shape        \n",
    "        # weight initialization        \n",
    "        self.W = np.zeros(self.n+1)        \n",
    "#         self.b = 0        \n",
    "        self.X = X.copy()\n",
    "        self.X['C'] = 1\n",
    "        self.Y = Y\n",
    "#         print(self.X)\n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            self.update_weights()            \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :\n",
    "\n",
    "#         A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
    "\n",
    "        A = 1 / ( 1 + np.exp( -self.X.dot( self.W ) ) )\n",
    "        # calculate gradients        \n",
    "        tmp = ( A - self.Y.T )\n",
    "\n",
    "        tmp = np.reshape(tmp, self.m)\n",
    "\n",
    "\n",
    "        dW = np.dot( self.X.T, tmp ) / self.m + self.reg / self.m\n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "        # update weights\n",
    "        self.W = self.W - self.learning_rate * dW \n",
    "        \n",
    "#         self.b = self.b - self.learning_rate * db\n",
    "        \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "      \n",
    "    def predict( self, X ) :    \n",
    "#         Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )     \n",
    "        X = X.copy()\n",
    "        \n",
    "        X[\"C\"] = 1\n",
    "        Z = 1 / ( 1 + np.exp( - X.dot( self.W )  ) )        \n",
    "\n",
    "        Y = np.where( Z > 0.5, 1, 0 )       \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e3324ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5448254e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460285132382892"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogitRegression( learning_rate = 0.001, iterations = 100 )\n",
    "model.fit( X_train, y_train )\n",
    "accuracy_score(y_test,model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf9a10b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460285132382892"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loj = LogisticRegression(solver = \"liblinear\")\n",
    "loj_model = loj.fit(X_train,y_train)\n",
    "loj_model\n",
    "\n",
    "testscore_lr =accuracy_score(y_test, loj_model.predict(X_test))\n",
    "accuracy_score(y_test, loj_model.predict(X_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871cce91",
   "metadata": {},
   "source": [
    "K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "55d1626b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9389002036659878"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_model = knn.fit(X_train, y_train)\n",
    "\n",
    "accuracy_score(y_test, knn_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35035e2",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a14848c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460285132382892"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel = \"linear\").fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d69dd",
   "metadata": {},
   "source": [
    "Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59203c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439918533604889"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbm_model.predict(X_test)\n",
    "testscore_gbm=accuracy_score(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e93029f",
   "metadata": {},
   "source": [
    "## Conclusion on Original Dataset:\n",
    "On the original dataset, all approaches have a impressive performance.\n",
    "It looks so succefully but I find the reason behind this false prosperity.\n",
    "It was because that the original dataset itself is a biased dataset.\n",
    "To allievate the bias of the dataset, I use Synthetic Minority Oversampling Technique (SMOTE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ae1c7",
   "metadata": {},
   "source": [
    "Train on Over-Sampling training set (X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb26b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8435adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_resample, y_resample = smote.fit_resample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7524b9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859470468431772"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogitRegression( learning_rate = 0.001, iterations = 20000 )\n",
    "\n",
    "model.fit(X_resample, y_resample)\n",
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "059251ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8004073319755601"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_model = knn.fit(X_resample, y_resample)\n",
    "\n",
    "accuracy_score(y_test, knn_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5bd08ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8065173116089613"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model = GradientBoostingClassifier().fit(X_resample, y_resample)\n",
    "\n",
    "accuracy_score(y_test,gbm_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0607c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:45:28] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9144602851323829"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_jobs=1).fit(X_resample, y_resample)\n",
    "\n",
    "accuracy_score(y_test,xgb_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041576b9",
   "metadata": {},
   "source": [
    "## Good test result on logistic regression\n",
    "How does your result compare to state-of-the-art results for that problem or dataset?\n",
    "The state-of-the-art is Extreme Gradient Boosting, which gained huge popularity during lots of data science competition. XGBoost scored 91.4% accuracy, slightly better than my approach. I am trying to implement XGBoost from sratch but I have not completed it in this project because of limitation of time.\n",
    "\n",
    "I tried many algorithms including Naive Bayes, Random Forest, SVM (Implemented in PS2) and selected three of them according to their performance\n",
    "I compared my result with approaches including K-Neighbors and gradient boost. My approach using logistic regression still did a better job than them, 88.6% vs around 80%. Nevertheless, it is possible that KNN and Gradient boost will get a better performance if they are finely tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d75edf8",
   "metadata": {},
   "source": [
    "The formulation of boost algorithm is different. Boost algorithm including gradient boost is a method of converting a set of weak learners into a strong learner. The performance would be great if the family of weak learners have a very small even no correlation between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad17fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
